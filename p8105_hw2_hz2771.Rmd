---
title: "p8105_hw2_hz2771"
author: 'Haolin Zhong (UNI: hz2771)'
date: "2021/10/1"
output: github_document
---

# Import required packages

```{r message=FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

## Use relative path to access the data file:

```{r}
data_path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

## Read and clean the Mr.Trash Wheel sheet:

```{r, warning = FALSE}
trash_wheel_df = 
  read_excel(data_path, 
             sheet = "Mr. Trash Wheel",
             range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls))
```

## Read and clean precipitation data for 2018 and 2019:

```{r}
precipitation_2019 =
  read_excel(data_path,
             sheet = "2019 Precipitation",
             skip = 1) %>%
  janitor::clean_names() %>% 
  drop_na(total, month) %>% 
  mutate(year = 2019)

precipitation_2018 = 
  read_excel(data_path,
             sheet = "2018 Precipitation",
             skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(total, month) %>% 
  mutate(year = 2018)
```

## Combine precipitation datasets and convert month to a character variable:

```{r}
precipitation_df = 
  bind_rows(precipitation_2018, precipitation_2019) %>% 
  mutate(month = month.name[month])
```

## Describe the dataset

The Mr.Trash Wheel dataset was generated by the water-wheel trash collector from 
the Inner Harbor in Baltimore, Maryland. This dataset contains weights, volumes,
and specific types of collected trash at a month-level granularity. Besides, 
year-level precipitation data is also contained.

- After data cleaning, Mr.Trash Wheel dataset contains `r nrows(trash_wheel_df)`
observations, and precipitation data for 2018 and 2019 contains 
`r nrows(precipitation_df)` observations.

- The total precipitation in 2018 is `r precipitation_df %>% filter(year == 2018) %>% pull(total) %>% sum()`.

- The median number of sports balls in a dumpster in 2017 is `r trash_wheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`.


# Problem 2

## Clean data in the `pol-month.csv`

```{r, warning=FALSE}
pols_path = "./data/fivethirtyeight_datasets/pols-month.csv"
pols_df = 
  read_csv(pols_path) %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(month = month.name[month],
         president = recode(prez_gop, `0` = "dem", `1` = "gop", `2` = "gop")) %>%
  select(-day, -starts_with("prez"))

```

## Clean data in the `snp.csv`

```{r, warning=FALSE}
snp_path = "./data/fivethirtyeight_datasets/snp.csv"
snp_df =
  read_csv(snp_path) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  relocate(year, month)
  
```

## Tidy up the unemployment data

```{r}
unepl_path = "./data/fivethirtyeight_datasets/unemployment.csv"
unepl_df = 
  read_csv(unepl_path) %>%
  pivot_longer(cols = "Jan":"Dec", names_to = "month", values_to = "unemployment_rate") %>% 
  mutate(month = month.name[which(month.abb == month)])


```




